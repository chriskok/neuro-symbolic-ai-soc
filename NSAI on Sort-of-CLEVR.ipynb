{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuro-Symbolic AI\n",
    "## Sort-of-CLEVR Dataset\n",
    "### Contents\n",
    "- Generate Dataset\n",
    "- Perception Module\n",
    "    - Train\n",
    "    - Inference\n",
    "- Semantic Parser\n",
    "    - Preprocess Data\n",
    "    - Train Seq2Seq Model\n",
    "    - Inference\n",
    "- Program Executor\n",
    "- Plugging Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Pytorch 1.7 and torchtext 0.8\n",
    "# !pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchtext==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/nerdimite/neuro-symbolic-ai-soc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd neuro-symbolic-ai-soc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import dlib\n",
    "import cv2\n",
    "from skimage.io import imshow\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as tfms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sample i.e.\n",
    "# a tuple of 1 image, 6 objects' properties, 20 QA vectors (10 relational and 10 non-relational)\n",
    "sample = build_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down the sample\n",
    "img, objects, queries, programs, answers = convert_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (img * 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25e513eeb20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([ 24, 140]), 'c', (9, 125, 39, 155)),\n",
       " (1, array([30, 79]), 'r', (15, 64, 45, 94)),\n",
       " (2, array([128, 138]), 'c', (113, 123, 143, 153)),\n",
       " (3, array([171, 172]), 'r', (156, 157, 186, 187)),\n",
       " (4, array([128,  23]), 'c', (113, 8, 143, 38)),\n",
       " (5, array([88, 15]), 'c', (73, 0, 103, 30))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is the closest shape to the orange object?',\n",
       "  'circle',\n",
       "  'filter orange <nxt> relate closest <nxt> query shape'),\n",
       " ('What is the furthest shape from the yellow object?',\n",
       "  'rectangle',\n",
       "  'filter yellow <nxt> relate furthest <nxt> query shape'),\n",
       " ('What is the furthest shape from the yellow object?',\n",
       "  'rectangle',\n",
       "  'filter yellow <nxt> relate furthest <nxt> query shape'),\n",
       " ('What is the furthest shape from the green object?',\n",
       "  'rectangle',\n",
       "  'filter green <nxt> relate furthest <nxt> query shape'),\n",
       " ('What is the furthest shape from the green object?',\n",
       "  'rectangle',\n",
       "  'filter green <nxt> relate furthest <nxt> query shape'),\n",
       " ('What is the furthest shape from the gray object?',\n",
       "  'circle',\n",
       "  'filter gray <nxt> relate furthest <nxt> query shape'),\n",
       " ('How many objects of the same shape as the red object are there?',\n",
       "  '4',\n",
       "  'filter red <nxt> query shape <nxt> filter <nxt> count'),\n",
       " ('What is the closest shape to the red object?',\n",
       "  'rectangle',\n",
       "  'filter red <nxt> relate closest <nxt> query shape'),\n",
       " ('What is the closest shape to the green object?',\n",
       "  'circle',\n",
       "  'filter green <nxt> relate closest <nxt> query shape'),\n",
       " ('How many objects of the same shape as the blue object are there?',\n",
       "  '4',\n",
       "  'filter blue <nxt> query shape <nxt> filter <nxt> count'),\n",
       " ('What is the shape of the yellow object?',\n",
       "  'circle',\n",
       "  'filter yellow <nxt> query shape'),\n",
       " ('Is there a red object on the top?',\n",
       "  'no',\n",
       "  'filter red <nxt> query position <nxt> isTop'),\n",
       " ('Is there a orange object on the left?',\n",
       "  'no',\n",
       "  'filter orange <nxt> query position <nxt> isLeft'),\n",
       " ('What is the shape of the red object?',\n",
       "  'circle',\n",
       "  'filter red <nxt> query shape'),\n",
       " ('Is there a yellow object on the left?',\n",
       "  'yes',\n",
       "  'filter yellow <nxt> query position <nxt> isLeft'),\n",
       " ('Is there a red object on the left?',\n",
       "  'yes',\n",
       "  'filter red <nxt> query position <nxt> isLeft'),\n",
       " ('Is there a green object on the top?',\n",
       "  'yes',\n",
       "  'filter green <nxt> query position <nxt> isTop'),\n",
       " ('Is there a blue object on the left?',\n",
       "  'no',\n",
       "  'filter blue <nxt> query position <nxt> isLeft'),\n",
       " ('Is there a orange object on the left?',\n",
       "  'no',\n",
       "  'filter orange <nxt> query position <nxt> isLeft'),\n",
       " ('Is there a yellow object on the left?',\n",
       "  'yes',\n",
       "  'filter yellow <nxt> query position <nxt> isLeft')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(queries, answers, programs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset\n",
    "n_train_imgs = 100\n",
    "n_test_imgs = 10\n",
    "\n",
    "build_dataset(n_train_imgs, data_dir='data/train', prefix='train')\n",
    "build_dataset(n_test_imgs, data_dir='data/test', prefix='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perception Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Object Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perception import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_data(csv_file, img_dir):\n",
    "    '''Load the image detection data for training the object detector'''\n",
    "    # Annotations\n",
    "    annot = pd.read_csv(csv_file)\n",
    "    \n",
    "    data = {}\n",
    "    for i in range(len(os.listdir(img_dir))):\n",
    "        # Get all rows belonging to the same scene\n",
    "        scene = annot[annot['filename'] == f'{i}.jpg']\n",
    "        # Read the image\n",
    "        img = cv2.imread(os.path.join(img_dir, f'{i}.jpg'))\n",
    "        \n",
    "        # Add bounding box information for dlib\n",
    "        bboxes = []\n",
    "        for row in scene.values:\n",
    "            x1, y1, x2, y2 = row[-4:]\n",
    "            dlib_box = dlib.rectangle(left=x1 , top=y1, right=x2, bottom=y2)\n",
    "            bboxes.append(dlib_box)\n",
    "        \n",
    "        data[i] = (img, bboxes)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Image Detection Data\n",
    "det_data = load_image_data('data/train/train_img_det.csv', 'data/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: precision: 1, recall: 1, average precision: 1\n",
      "Saved the model to detector.svm\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the Model\n",
    "train_detector(det_data, 'detector.svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binarize():\n",
    "    '''PyTorch Transforms Object'''\n",
    "    def __init__(self):\n",
    "        '''Converts Grayscale to Binary (except white every other color is zeroed)'''\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, img_tensor):\n",
    "        '''\n",
    "        Args:\n",
    "            img_tensor (tensor): 0-1 scaled tensor with 1 channel\n",
    "        Returns:\n",
    "            tensor\n",
    "        '''\n",
    "        return (img_tensor > 0.95).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "shapes_data = ImageFolder('data/shapes_data/', transform=tfms.Compose([tfms.Grayscale(), \n",
    "                                                                       tfms.Resize((40, 40)), \n",
    "                                                                       tfms.ToTensor(),\n",
    "                                                                       Binarize()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'circle': 0, 'rectangle': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader\n",
    "shapes_loader = DataLoader(shapes_data, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "shape_classifier = ShapeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ckkok\\Anaconda3\\envs\\nesy\\lib\\site-packages\\torch\\cuda\\__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f97b76ec22245e1befce4c58f9a6bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Mean Loss = 0.6924034655094147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738aacaa526b4ad5bc69e11230c986c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Mean Loss = 0.5056794484456381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e3df3f6dab42c5baebcb156659ca96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Mean Loss = 0.39713239669799805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315d9ee24f1e4e14b807b59d23fe7240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Mean Loss = 0.27521824340025586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea81ecb7c0564889802b32b887d6dcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Mean Loss = 0.20599343379338583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2596cfd64a1d45edbbea99360abe75e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Mean Loss = 0.1625971421599388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad2e0e430664d7a8de9b07d59ae64e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Mean Loss = 0.12339496488372485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0193273bc94adb9862193ba58ad610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Mean Loss = 0.11831382662057877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c9793abe4349c3948783ba9c57d494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Mean Loss = 0.08321695774793625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63cfe1f0cca4a8d87369842082431f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Mean Loss = 0.0664023719727993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a848662f498649c388e16db71e19df4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Mean Loss = 0.04903212903688351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf7b225f14949c6b8888f458bc4414c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Mean Loss = 0.04522654631485542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e8294059894b83848f79e2b0db082b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Mean Loss = 0.04037094737092654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4494026640e4f5ebca2345ff63d8c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Mean Loss = 0.030688407210012276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0865bd9414410ea9f2722e0b5923b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Mean Loss = 0.026662912219762802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9eebf5eb6fc4ad285517f91b28ee119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Mean Loss = 0.026272069662809372\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ff71138e664b33bbf8cac53301db4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Mean Loss = 0.024116359728698928\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc077a4747894cfcaa88df4c7bd6c913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Mean Loss = 0.021752340874324243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aa71fc154d44579c4da1d4c8b89264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Mean Loss = 0.023818855949987967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634cc35c16424bc5891338e8ed370b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Mean Loss = 0.04330310535927614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ebc469905f4d5cab170c2429fd5249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Mean Loss = 0.05332726597165068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee389e3cbd1842a084b33de3ceb4c61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Mean Loss = 0.020736787701025605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea66a13a8a34f8fbb5aaa2dc6db76e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Mean Loss = 0.014219415684541067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9039cf1fd44ea6873f6f7bb7721862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Mean Loss = 0.009915985244636735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a714433cb8da45f7b5e5326378cf3369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Mean Loss = 0.00839224566395084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d869ba63b549aa8fea8f419edcd828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Mean Loss = 0.00670825286457936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99d099aab6b496381d4e11b8042b83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Mean Loss = 0.007912625364648799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0198470387e64a2da2fa49394daa04a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Mean Loss = 0.00941873217622439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ce8ed6cd4844d2b3754681a55c3536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Mean Loss = 0.0089214484517773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be04e45c89c84b9ba592b6c122451b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Mean Loss = 0.009996723926936587\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee6ae18230a40ff985c6049c84b81aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Mean Loss = 0.010567404252166549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66266c43d7cf4ac8bb0fa68ae6636bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Mean Loss = 0.01121387374587357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9429b113e59648bfb8d8b916250222ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Mean Loss = 0.014425224255925665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd77aa4bb0c497c9d143fc15714f196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Mean Loss = 0.019114165644471843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed479ba89492421cb6d89ee68fbf48e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Mean Loss = 0.010005537866769979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f419ddd2f984fee86e78050c9fa976f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Mean Loss = 0.009008582467989376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a1a1f915fd4ed9a8b71133f99c7071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Mean Loss = 0.00905815300454075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69081f765e9c4ecea80bea49942b98fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Mean Loss = 0.00828766580283021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9f8b5976bf47119dc3a38decb5f0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Mean Loss = 0.006297932122834027\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8735f906f4514d6fba4040a6265efd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Mean Loss = 0.007498936417202155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d3ec4bf1c34a13a9f1a6567cf88c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Mean Loss = 0.004851491559141626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2068294e57467e9a44decd8d6fd7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Mean Loss = 0.0038346275493192175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d756f578f9043b9b058f32787e7b0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Mean Loss = 0.002624196272032956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e478266019c48ca87651a86a8903a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Mean Loss = 0.0014955790247768164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0ed6f55f5245d69899a6c2a427c153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Mean Loss = 0.0014966154800883185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e300153e71d249e3b958422aef6b4615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Mean Loss = 0.0011581106688633251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe124d7480d4cea8ce03a3a06b85509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Mean Loss = 0.001009752542207328\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f929a2150d04536bb6290c7847b6ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Mean Loss = 0.004257702559698373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83a08982e594730ae6e8d5540cffcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Mean Loss = 0.0031281762348953635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f9c2f6e8504f96b1576c15d067e188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Mean Loss = 0.0015372264994463574\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "shape_classifier.train_classifier(shapes_loader, lr=0.0001, epochs=50, filename='classifier.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perception Pipeline\n",
    "`detector -> attribute (shape and color) extraction -> structural scene representation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "perceiver = PerceptionPipe('detector.svm', 'classifier.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [  0, 156, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  (171, 172)),\n",
       " (array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  (127, 20)),\n",
       " (array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  (23, 140)),\n",
       " (array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  (127, 136)),\n",
       " (array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [  0, 255,   0],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  (31, 80)),\n",
       " (array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  (87, 17))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference with Detector\n",
    "objects = perceiver.detect(img)\n",
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the isolated objects (this will not work in colab as its headless)\n",
    "# for obj, _ in objects:\n",
    "#     cv2.imshow('frame', obj)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = circle\n",
      "Color = blue\n"
     ]
    }
   ],
   "source": [
    "# Inference with Attribute Extractor (Shape Classifier, Color Extractor)\n",
    "shape, color = perceiver.extract_attributes(objects[3][0])\n",
    "print(f'Shape = {shape}\\nColor = {color}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape</th>\n",
       "      <th>color</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rectangle</td>\n",
       "      <td>orange</td>\n",
       "      <td>(171, 172)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>circle</td>\n",
       "      <td>gray</td>\n",
       "      <td>(127, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>circle</td>\n",
       "      <td>red</td>\n",
       "      <td>(23, 140)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>circle</td>\n",
       "      <td>blue</td>\n",
       "      <td>(127, 136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rectangle</td>\n",
       "      <td>green</td>\n",
       "      <td>(31, 80)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>circle</td>\n",
       "      <td>yellow</td>\n",
       "      <td>(87, 17)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shape   color    position\n",
       "0  rectangle  orange  (171, 172)\n",
       "1     circle    gray   (127, 20)\n",
       "2     circle     red   (23, 140)\n",
       "3     circle    blue  (127, 136)\n",
       "4  rectangle   green    (31, 80)\n",
       "5     circle  yellow    (87, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene = perceiver.scene_repr(img)\n",
    "scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_parser import *\n",
    "from torchtext.legacy.data import BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the preprocessor object and preprocess\n",
    "preproc = Preprocessor('data/train/train_q2p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset object\n",
    "train_data = preproc.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x0000025E665C0AC0>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             '<sos>': 2,\n",
       "             '<eos>': 3,\n",
       "             '<nxt>': 4,\n",
       "             'filter': 5,\n",
       "             'query': 6,\n",
       "             'shape': 7,\n",
       "             'position': 8,\n",
       "             'relate': 9,\n",
       "             'orange': 10,\n",
       "             'gray': 11,\n",
       "             'count': 12,\n",
       "             'isleft': 13,\n",
       "             'istop': 14,\n",
       "             'closest': 15,\n",
       "             'red': 16,\n",
       "             'yellow': 17,\n",
       "             'furthest': 18,\n",
       "             'blue': 19,\n",
       "             'green': 20})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the Vocabulary\n",
    "preproc.prog_f.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x0000025E5145DE80>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             '<sos>': 2,\n",
       "             '<eos>': 3,\n",
       "             'the': 4,\n",
       "             '?': 5,\n",
       "             'object': 6,\n",
       "             'is': 7,\n",
       "             'shape': 8,\n",
       "             'there': 9,\n",
       "             'what': 10,\n",
       "             'a': 11,\n",
       "             'on': 12,\n",
       "             'of': 13,\n",
       "             'orange': 14,\n",
       "             'gray': 15,\n",
       "             'are': 16,\n",
       "             'as': 17,\n",
       "             'how': 18,\n",
       "             'many': 19,\n",
       "             'objects': 20,\n",
       "             'same': 21,\n",
       "             'left': 22,\n",
       "             'top': 23,\n",
       "             'closest': 24,\n",
       "             'to': 25,\n",
       "             'red': 26,\n",
       "             'yellow': 27,\n",
       "             'from': 28,\n",
       "             'furthest': 29,\n",
       "             'blue': 30,\n",
       "             'green': 31})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the Vocabulary\n",
    "preproc.que_f.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 3\n",
    "learning_rate = 3e-4\n",
    "batch_size = 8\n",
    "num_steps = len(train_data) / batch_size\n",
    "\n",
    "# Model hyperparameters\n",
    "config = {\n",
    "    'que_vocab_size': len(preproc.que_f.vocab),\n",
    "    'prog_vocab_size': len(preproc.prog_f.vocab),\n",
    "    'embedding_dim': 256,\n",
    "    'num_heads': 8,\n",
    "    'num_encoder_layers': 3,\n",
    "    'num_decoder_layers': 3,\n",
    "    'dropout': 0.10,\n",
    "    'max_len': 20,\n",
    "    'forward_expansion': 4,\n",
    "    'que_pad_idx': preproc.que_f.vocab.stoi[\"<pad>\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the config as a json file\n",
    "import json\n",
    "with open('config.json', 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training Generator\n",
    "train_loader = BucketIterator.splits((train_data,),\n",
    "                                     batch_size=batch_size,\n",
    "                                     sort_within_batch=True,\n",
    "                                     sort_key=lambda x: len(x.query),\n",
    "                                     device=device)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "seq2seq = Seq2Seq(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e82aa7648b44081bb9d2bd50a97da4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/250.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Mean Loss = 0.26198345557041464\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019aa547c0d94d69b62f3145ef03e489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/250.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Mean Loss = 0.0021505087879486384\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a2391b358342fd98ed2c44f7255b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/250.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Mean Loss = 0.0009279818390496075\n",
      "\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train Model\n",
    "seq2seq.train_model(train_loader, num_epochs, num_steps, filename='semantic_parser.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_parser = SemanticParser(preproc, config, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filter green', 'relate furthest', 'query shape']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program = sem_parser.predict('What is the furthest shape from the green object?')\n",
    "program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from program_executor import ProgramExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = ProgramExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the closest shape to the orange object?',\n",
       " 'What is the furthest shape from the yellow object?',\n",
       " 'What is the furthest shape from the yellow object?',\n",
       " 'What is the furthest shape from the green object?',\n",
       " 'What is the furthest shape from the green object?',\n",
       " 'What is the furthest shape from the gray object?',\n",
       " 'How many objects of the same shape as the red object are there?',\n",
       " 'What is the closest shape to the red object?',\n",
       " 'What is the closest shape to the green object?',\n",
       " 'How many objects of the same shape as the blue object are there?',\n",
       " 'What is the shape of the yellow object?',\n",
       " 'Is there a red object on the top?',\n",
       " 'Is there a orange object on the left?',\n",
       " 'What is the shape of the red object?',\n",
       " 'Is there a yellow object on the left?',\n",
       " 'Is there a red object on the left?',\n",
       " 'Is there a green object on the top?',\n",
       " 'Is there a blue object on the left?',\n",
       " 'Is there a orange object on the left?',\n",
       " 'Is there a yellow object on the left?']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the program executor with on a full sample of 20 queries\n",
    "pred_ans = []\n",
    "for que in queries:\n",
    "    program = sem_parser.predict(que)\n",
    "    pred_ans.append(executor(scene, program))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('circle', 'circle'),\n",
       " ('rectangle', 'rectangle'),\n",
       " ('rectangle', 'rectangle'),\n",
       " ('rectangle', 'rectangle'),\n",
       " ('rectangle', 'rectangle'),\n",
       " ('circle', 'circle'),\n",
       " (4, '4'),\n",
       " ('rectangle', 'rectangle'),\n",
       " ('circle', 'circle'),\n",
       " (4, '4'),\n",
       " ('circle', 'circle'),\n",
       " ('no', 'no'),\n",
       " ('no', 'no'),\n",
       " ('circle', 'circle'),\n",
       " ('yes', 'yes'),\n",
       " ('yes', 'yes'),\n",
       " ('yes', 'yes'),\n",
       " ('no', 'no'),\n",
       " ('no', 'no'),\n",
       " ('yes', 'yes')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(pred_ans, answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plugging Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from program_executor import *\n",
    "from perception import *\n",
    "from semantic_parser import *\n",
    "import torch\n",
    "from skimage.io import imshow\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config file for transformers\n",
    "import json\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSAIPipeline():\n",
    "    '''End-to-End Pipeline of Neuro-Symbolic AI on Sort-of-CLEVR dataset'''\n",
    "    def __init__(self, \n",
    "                 config,\n",
    "                 detector='models/detector.svm',\n",
    "                 classifier='models/classifier.pth',\n",
    "                 sem_parser='models/semantic_parser.pth',\n",
    "                 train_csv='data/train/train_q2p.csv',\n",
    "                 device=None):\n",
    "        \n",
    "        if device is None:\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.device = device\n",
    "        \n",
    "        # Perception Module\n",
    "        self.perceiver = PerceptionPipe(detector, classifier, self.device)\n",
    "        \n",
    "        # Semantic Parser\n",
    "        self.preproc = Preprocessor(train_csv)\n",
    "        self.sem_parser = SemanticParser(self.preproc, config, filename=sem_parser, device=self.device)\n",
    "        \n",
    "        # Program Executor\n",
    "        self.executor = ProgramExecutor()\n",
    "        \n",
    "    def predict(self, img, query):\n",
    "        '''\n",
    "        Make Prediction on a single image and question pair\n",
    "        \n",
    "        Args:\n",
    "            img (str/array): pixel values should be in 0-255 range\n",
    "                             of dtype uint8 in BGR color format or\n",
    "                             file path of the image\n",
    "            query (str): question about the image\n",
    "            \n",
    "        Returns:\n",
    "            str: answer of the query\n",
    "        '''\n",
    "        # Load img if it's a path\n",
    "        if type(img) == str:\n",
    "            img = cv2.imread(img)\n",
    "        \n",
    "        # Structured Scene Representation\n",
    "        scene = self.perceiver.scene_repr(img)\n",
    "        # Synthesize Program from Query\n",
    "        program = self.sem_parser.predict(query)\n",
    "        # Execute Program\n",
    "        answer = self.executor(scene, program)\n",
    "        \n",
    "        return answer, program\n",
    "    \n",
    "    def evaluate(self, csv, img_dir, debug=True):\n",
    "        '''\n",
    "        Evaluate the model on a dataset\n",
    "        \n",
    "        Args:\n",
    "            csv (str): path of the csv containing image filename, answer, query and program\n",
    "            img_dir (str): directory containing the images\n",
    "            debug (bool): View the data points which were wrong\n",
    "        Returns:\n",
    "            int: accuracy of the model\n",
    "        '''\n",
    "        data = pd.read_csv(csv).values\n",
    "        \n",
    "        correct = []\n",
    "        for filename, answer, query, program in tqdm(data):\n",
    "            # Load Image\n",
    "            img_path = os.path.join(img_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            # Make prediction\n",
    "            pred, pred_prog = self.predict(img, query)\n",
    "            \n",
    "            # Verify answer\n",
    "            if str(pred) == answer:\n",
    "                correct.append(1)\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(filename, answer, pred, query, pred_prog)\n",
    "                correct.append(0)\n",
    "        \n",
    "        acc = (sum(correct) / len(correct)) * 100\n",
    "        \n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11132/959565150.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnsai\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNSAIPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11132/627035673.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, detector, classifier, sem_parser, train_csv, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Perception Module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperceiver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptionPipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Semantic Parser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\neuro-symbolic-ai-soc\\perception.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, detector_file, classifer_file, device)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# Shape Classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShapeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifer_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nesy\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nesy\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nesy\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nesy\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(data_type, size, key, location)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m         \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nesy\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nesy\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nesy\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[0;32m    136\u001b[0m                            \u001b[1;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                            \u001b[1;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "nsai = NSAIPipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsai.predict('data/test/images/1.jpg', 'How many objects of the same shape as the gray object are there?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nsai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11132/39214308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluate on the test and get the accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnsai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/test/test_q2p.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data/test/images/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nsai' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test and get the accuracy\n",
    "nsai.evaluate('data/test/test_q2p.csv', 'data/test/images/', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread('data/train/images/2.jpg')\n",
    "imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsai.executor.scene = nsai.perceiver.scene_repr(img2)\n",
    "nsai.executor.scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# program = nsai.sem_parser.predict('How many objects of the same shape as the red object are there? ')\n",
    "# program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsai.executor.count(nsai.executor.filter_(nsai.executor.query(nsai.executor.filter_('red'), 'shape')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
